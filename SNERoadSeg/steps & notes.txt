Step 1 - Go through code
Step 2 - create block diagram of code flow (do in tandem with step 1)
Step 3 - run with pretrained weights
Step 3.5? - train different training and testing split?
Step 4 - look into how difficult to train with AdaBins (figure out what bits of code need to be replaced)
Step 5 - Figure out training and non training split
Step 6 - make sure image sizes align for code rerunning
Step 7 - Use mapping file for raw to road dataset mapping

Notes:
1 - Depth map uses /1000 decoding vs 256 for KITTI MDE and AdaBins
2 - Depth map has top of images blacked out (set to inf?) - will non blacked out depths affect results?
3 - 8 neighbouring pixels (3 x 3 grid with centred pixel being P) used to estimate normal. Qi-P gives us the direction of the vector that we need to get the normal for. Gradient is used since it's basically giving us the x and y components of the Qi-P,
4 - Looks like input image needs to be divisible by 32. Reason being, if you look at the model architecture, the pooling layers eventiually get to a point where they are 1/32 the size of the original model


Code Changes:
1 - Changed root_children to net in line 55 @ networks.py
2 - Changed GPU ids in base options default value from 0 to -1
3 - Changed num threads to 0 from 1 in test.py due to no multiprocessing support on Mac (vs Linux/Ubuntu)